{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T16:27:20.885828Z",
     "start_time": "2025-05-25T16:27:00.179685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from datetime import datetime, date\n",
    "warnings.filterwarnings(\"ignore\", message=\"`result_format` configured at the Validator-level*\")\n",
    "\n",
    "# Load the data\n",
    "#df = pd.read_csv(\"./data/transactions.csv\")\n",
    "transaction_df = pd.read_csv(\"./data/transactions.csv\", dtype=\"string\")\n",
    "account_df = pd.read_csv(\"./data/sebank_customers_with_accounts.csv\", dtype=\"string\")\n",
    "error_columns = list(transaction_df.columns) + ['error notes']\n",
    "transaction_error_df = pd.DataFrame(columns=error_columns)\n",
    "\n",
    "def progress_bar(current, percent):\n",
    "    temp_count =int(current/percent)\n",
    "    bar_percent = int(temp_count / 10)\n",
    "    bar = \"█\" * bar_percent\n",
    "    if  percent != 0 and current % percent == 0 :\n",
    "        if temp_count % 10 >= 5:\n",
    "            bar = bar + \"▌\"\n",
    "        print(f\"{temp_count}% {bar}\",)\n",
    "\n",
    "for column in transaction_df:\n",
    "    if column == \"amount\": #removes spacing errors from the amount column\n",
    "        transaction_df[column] = transaction_df[column].astype(str).str.replace(\" \",\"\")\n",
    "    elif column == \"timestamp\":\n",
    "        transaction_df[column] = transaction_df[column].astype(str).str.replace(\"-\",\"\")\n",
    "        transaction_df[column] = transaction_df[column].astype(str).str.replace(\".\",\":\")\n",
    "    transaction_df[column] = transaction_df[column].astype(str).str.strip()\n",
    "    #print(transaction_df[column].head())\n",
    "\n",
    "#data conversion\n",
    "transaction_df[\"amount\"] = pd.to_numeric(transaction_df[\"amount\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "for index in range(transaction_df.shape[0]):\n",
    "    row = transaction_df.loc[index]\n",
    "    if pd.isna(transaction_df.loc[index, 'notes']):\n",
    "        transaction_df.loc[index, 'notes'] = \"no notes\"\n",
    "    if row.isna().any():\n",
    "        temp_row = transaction_df.iloc[[index]].copy()\n",
    "        temp_row = row.fillna(\"missing data\")\n",
    "        temp_row[index,\"error notes\"] = \"missing data\"\n",
    "        transaction_error_df = pd.concat([transaction_error_df, temp_row], ignore_index=True)\n",
    "        transaction_df.drop(index, inplace=True)\n",
    "        print(f\"missing data: {index}\")\n",
    "        progress_bar(index, 1000)\n",
    "        continue\n",
    "    #end of timestamp empty check\n",
    "    temp_list = str(transaction_df.loc[index,'timestamp']).split()\n",
    "    temp_date = temp_list[0]\n",
    "    temp_time = temp_list[1]\n",
    "    datetime_corrected = False\n",
    "    if len(temp_list[0]) == 6:\n",
    "        datetime_corrected = True\n",
    "        temp_date = \"20\" + temp_list[0]\n",
    "        if datetime.strptime(temp_date, \"%Y%m%d\").date() > date.today():\n",
    "            temp_date = \"19\" + temp_list[0]\n",
    "            #end of date length check if-statement\n",
    "    if len(temp_list[1]) == 5:\n",
    "        datetime_corrected = True\n",
    "        temp_time = temp_list[1] + \":00\"\n",
    "        #end of date length check if-statement\n",
    "    if datetime_corrected:\n",
    "        temp_timestamp = temp_date + \" \" + temp_time\n",
    "        transaction_df.loc[index,'timestamp'] = temp_timestamp\n",
    "    try:\n",
    "        transaction_df.loc[index,'timestamp'] = pd.to_datetime(transaction_df.loc[index,'timestamp'], format=\"%Y%m%d %H:%M:%S\", errors=\"raise\")\n",
    "    except ValueError as e:\n",
    "        temp_row = transaction_df.iloc[[index]].copy()\n",
    "        temp_row[\"error notes\"] = \"invalid timestamp format\"\n",
    "        transaction_error_df = pd.concat([transaction_error_df, temp_row], ignore_index=True)\n",
    "        transaction_df.drop(index, inplace=True)\n",
    "        print(f\"incorrect timestamp {index}\")\n",
    "        progress_bar(index, 1000)\n",
    "        continue\n",
    "    progress_bar(index, 1000)\n",
    "\n",
    "\n",
    "print(transaction_df.head())\n",
    "print(transaction_error_df.head())\n",
    "# Create the ephemeral GX context\n",
    "context = gx.get_context()\n",
    "\n",
    "# Add a pandas datasource\n",
    "data_source = context.data_sources.add_pandas(name=\"pandas\")\n",
    "\n",
    "# Add a dataframe asset\n",
    "data_asset = data_source.add_dataframe_asset(name=\"transactions_data\")\n",
    "\n",
    "# Define the batch (entire DataFrame)\n",
    "batch_definition = data_asset.add_batch_definition_whole_dataframe(name=\"batch_def\")\n",
    "batch = batch_definition.get_batch(batch_parameters={\"dataframe\": transaction_df})\n",
    "\n",
    "# Create the expectation suite with a name\n",
    "suite = gx.core.expectation_suite.ExpectationSuite(name=\"transactions_suite\")\n",
    "\n",
    "# Get the validator using the suite\n",
    "validator = context.get_validator(batch=batch, expectation_suite=suite)\n",
    "\n",
    "# Add expectations\n",
    "validator.expect_column_values_to_be_between(\"amount\", min_value=0.01, max_value=100000)\n",
    "validator.expect_column_values_to_not_be_null(\"timestamp\")\n",
    "\n",
    "# Validate\n",
    "results = validator.validate()\n",
    "\n",
    "# Print results\n",
    "print(results)"
   ],
   "id": "9b161146e31e5eaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfrif\\AppData\\Local\\Temp\\ipykernel_10452\\4256989140.py:73: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  transaction_error_df = pd.concat([transaction_error_df, temp_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect timestamp 821\n",
      "incorrect timestamp 866\n",
      "incorrect timestamp 876\n",
      "incorrect timestamp 884\n",
      "incorrect timestamp 911\n",
      "incorrect timestamp 913\n",
      "1% \n",
      "incorrect timestamp 1428\n",
      "2% \n",
      "3% \n",
      "4% \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_10452\\4256989140.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     66\u001B[39m         temp_timestamp = temp_date + \u001B[33m\" \"\u001B[39m + temp_time\n\u001B[32m     67\u001B[39m         transaction_df.loc[index,\u001B[33m'timestamp'\u001B[39m] = temp_timestamp\n\u001B[32m     68\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     69\u001B[39m         transaction_df.loc[index,\u001B[33m'timestamp'\u001B[39m] = pd.to_datetime(transaction_df.loc[index,\u001B[33m'timestamp'\u001B[39m], format=\u001B[33m\"%Y%m%d %H:%M:%S\"\u001B[39m, errors=\u001B[33m\"raise\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m70\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m ValueError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     71\u001B[39m         temp_row = transaction_df.iloc[[index]].copy()\n\u001B[32m     72\u001B[39m         temp_row[\u001B[33m\"error notes\"\u001B[39m] = \u001B[33m\"invalid timestamp format\"\u001B[39m\n\u001B[32m     73\u001B[39m         transaction_error_df = pd.concat([transaction_error_df, temp_row], ignore_index=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[32m~\\Documents\\TUC\\Datakvalitet\\Project Uppgifter\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, key, value)\u001B[39m\n\u001B[32m    881\u001B[39m         indexer = self._get_setitem_indexer(key)\n\u001B[32m    882\u001B[39m         self._has_valid_setitem_indexer(key)\n\u001B[32m    883\u001B[39m \n\u001B[32m    884\u001B[39m         iloc = self \u001B[38;5;28;01mif\u001B[39;00m self.name == \u001B[33m\"iloc\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m self.obj.iloc\n\u001B[32m--> \u001B[39m\u001B[32m885\u001B[39m         iloc._setitem_with_indexer(indexer, value, self.name)\n",
      "\u001B[32m~\\Documents\\TUC\\Datakvalitet\\Project Uppgifter\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, indexer, value, name)\u001B[39m\n\u001B[32m   1889\u001B[39m \n\u001B[32m   1890\u001B[39m         \u001B[38;5;66;03m# align and set the values\u001B[39;00m\n\u001B[32m   1891\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m take_split_path:\n\u001B[32m   1892\u001B[39m             \u001B[38;5;66;03m# We have to operate column-wise\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1893\u001B[39m             self._setitem_with_indexer_split_path(indexer, value, name)\n\u001B[32m   1894\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1895\u001B[39m             self._setitem_single_block(indexer, value, name)\n",
      "\u001B[32m~\\Documents\\TUC\\Datakvalitet\\Project Uppgifter\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, indexer, value, name)\u001B[39m\n\u001B[32m   1982\u001B[39m \n\u001B[32m   1983\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1984\u001B[39m             \u001B[38;5;66;03m# scalar value\u001B[39;00m\n\u001B[32m   1985\u001B[39m             \u001B[38;5;28;01mfor\u001B[39;00m loc \u001B[38;5;28;01min\u001B[39;00m ilocs:\n\u001B[32m-> \u001B[39m\u001B[32m1986\u001B[39m                 self._setitem_single_column(loc, value, pi)\n",
      "\u001B[32m~\\Documents\\TUC\\Datakvalitet\\Project Uppgifter\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, loc, value, plane_indexer)\u001B[39m\n\u001B[32m   2093\u001B[39m             \u001B[38;5;66;03m# set value into the column (first attempting to operate inplace, then\u001B[39;00m\n\u001B[32m   2094\u001B[39m             \u001B[38;5;66;03m#  falling back to casting if necessary)\u001B[39;00m\n\u001B[32m   2095\u001B[39m             self.obj._mgr.column_setitem(loc, plane_indexer, value)\n\u001B[32m   2096\u001B[39m \n\u001B[32m-> \u001B[39m\u001B[32m2097\u001B[39m         self.obj._clear_item_cache()\n",
      "\u001B[32m~\\Documents\\TUC\\Datakvalitet\\Project Uppgifter\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m4399\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m _clear_item_cache(self) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4400\u001B[39m         self._item_cache.clear()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
